{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# README:\n",
        "Upload the damaged painting and damage mask for inpainting"
      ],
      "metadata": {
        "id": "jGhAUQk3jnAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers transformers accelerate torch pillow matplotlib"
      ],
      "metadata": {
        "id": "Vzfm2nNYXeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import tensorflow as tf\n",
        "from huggingface_hub import hf_hub_download, HfApi\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline\n",
        "from google.colab import files\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ],
      "metadata": {
        "id": "9m5wYJhvXjy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your image\n",
        "print(\"Please upload your painting:\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "original_image = Image.open(io.BytesIO(uploaded[image_path])).convert(\"RGB\")\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(original_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dgGMYQ8oYIjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Please upload an existing mask (white=area to fill)\")\n",
        "\n",
        "uploaded_mask = files.upload()\n",
        "mask_path = next(iter(uploaded_mask))\n",
        "mask_image = Image.open(io.BytesIO(uploaded_mask[mask_path])).convert(\"L\")\n",
        "\n",
        "# Convert mask to binary (white=255, black=0)\n",
        "mask_array = np.array(mask_image)\n",
        "mask_array = np.where(mask_array > 128, 255, 0)\n",
        "mask_image = Image.fromarray(mask_array.astype(np.uint8))\n",
        "\n",
        "# Display mask\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(mask_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n3MLWQqUYOzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier for art movement\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"maximiliannl/art_movement_classifier\",\n",
        "    filename=\"trained_cnn_final_8_13.pth\",\n",
        "    revision=\"main\"\n",
        ")\n",
        "print(f\"Model downloaded to: {model_path}\")"
      ],
      "metadata": {
        "id": "zDAgrZQO1ESf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1), # [B,16,1024,1024]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # [B,16,512,512]\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # [B,32,256,256]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # [B,32,128,128]\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # [B,64,64,64]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # [B,64,32,32]\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*32*32, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Download model from Hugging Face Hub\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"maximiliannl/art_movement_classifier\",\n",
        "    filename=\"trained_cnn_final_8_13.pth\",\n",
        "    revision=\"main\"\n",
        ")\n",
        "print(f\"Model downloaded to: {model_path}\")\n",
        "\n",
        "# Load the model\n",
        "model_for_classification = SimpleCNN(num_classes=10).to(device)\n",
        "model_for_classification.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model_for_classification.eval()\n",
        "\n",
        "# Verify the model is loaded correctly\n",
        "print(\"Model successfully loaded from Hugging Face Hub!\")"
      ],
      "metadata": {
        "id": "23krxB-O1vuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((2048, 2048)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def classify_existing_image(image):\n",
        "    try:\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image = Image.fromarray(image)\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        # Preprocess image\n",
        "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        print(f\"Input tensor shape: {image_tensor.shape}\")\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            output = model_for_classification(image_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "\n",
        "        class_names = [\n",
        "            \"cubism\", \"dada\", \"early_modern\", \"impressionist\", \"medieval\",\n",
        "            \"minimalism\", \"realism\", \"renaissance\", \"romantic\", \"symbolism\"\n",
        "        ]\n",
        "\n",
        "        predicted_class = class_names[torch.argmax(probabilities).item()]\n",
        "        display(image)\n",
        "        print(f\"Predicted class: {predicted_class}\")\n",
        "        print(\"Class probabilities:\")\n",
        "        for i, prob in enumerate(probabilities):\n",
        "            print(f\"{class_names[i]}: {prob.item():.4f}\")\n",
        "        return predicted_class\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during classification: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"Classifying your existing image...\")\n",
        "movement_prediction = classify_existing_image(original_image)"
      ],
      "metadata": {
        "id": "q80MRzQFl8PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the inpainting pipeline\n",
        "model_id = f\"maximiliannl/{movement_prediction}_expert\"  # Your fine-tuned model\n",
        "\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Enable attention slicing if you get memory errors\n",
        "pipe.enable_attention_slicing()"
      ],
      "metadata": {
        "id": "4tMb2NhYX6US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inpainting with simple prompt and negative prompt\n",
        "prompt = f\"Carefully restore and complete this {movement_prediction} era artwork in a manner that preserves its original composition, brushwork, and textures, emphasizing historical accuracy, authentic color palettes, and fine detail true to the {movement_prediction} period.\"\n",
        "negative_prompt = \"blurry, distorted, artifacts, bad quality, text, watermark\"\n",
        "\n",
        "# Resize to multiples of 8 (better for diffusion models)\n",
        "width, height = original_image.size\n",
        "new_width = width - (width % 8)\n",
        "new_height = height - (height % 8)\n",
        "resized_image = original_image.resize((new_width, new_height))\n",
        "resized_mask = mask_image.resize((new_width, new_height))\n",
        "\n",
        "# Generate\n",
        "result = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=resized_image,\n",
        "    mask_image=resized_mask,\n",
        "    guidance_scale=17.5,\n",
        "    num_inference_steps=50\n",
        ").images[0]\n",
        "\n",
        "# Resize back to original dimensions if needed\n",
        "result = result.resize(original_image.size)"
      ],
      "metadata": {
        "id": "uP_twCRaYT6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display and save results\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(mask_image, cmap='gray')\n",
        "plt.title(\"Mask (white=inpainted area)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(result)\n",
        "plt.title(\"Inpainted Result\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save result\n",
        "result.save(\"inpainted_result.png\")\n",
        "print(\"Saved as 'inpainted_result.png'\")\n",
        "files.download(\"inpainted_result.png\")"
      ],
      "metadata": {
        "id": "hEuzYvi6Ybjr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}